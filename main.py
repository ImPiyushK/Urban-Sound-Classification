# -*- coding: utf-8 -*-
"""Getting Started with Audio Data Analysis using Deep Learning.ipynb

Automatically generated by Colaboratory.

"""

cd /content/drive/My Drive

import IPython.display as ipd
ipd.Audio('/content/drive/My Drive/Train/59.wav')

import os
import pandas as pd
import glob 
import librosa
import librosa.display
import matplotlib.pyplot as plt

#visulization
data, sampling_rate = librosa.load('/content/drive/My Drive/Train/59.wav')

plt.figure(figsize=(12, 4))
librosa.display.waveplot(data, sr=sampling_rate)

#displaying random audio files
import random

train = pd.read_csv('/content/drive/My Drive/train.csv') 

i = random.choice(train.index)

data_dir = '/content/drive/My Drive'

audio_name = train.ID[i]

path = os.path.join(data_dir, 'Train', str(audio_name) + '.wav')

print('ID: ', train.ID[i])
print('Class: ', train.Class[i])
x, sr = librosa.load('/content/drive/My Drive/Train/' + str(train.ID[i]) + '.wav')

plt.figure(figsize=(12, 4))
librosa.display.waveplot(x, sr=sr)

train.Class.value_counts()

test = pd.read_csv('/content/drive/My Drive/test.csv')
test['Class'] = 'jackhammer'
test.to_csv('sub01.csv', index=False)

data_dir = '/content/drive/My Drive/'
import numpy as np

def parser(row):
    file_name = os.path.join(os.path.abspath(data_dir), 'Train', str(row.ID) + '.wav')

    try:
        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')
        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) 
    except Exception as e:
        print("Error encountered while parsing file: ", file_name)
        return None, None

    feature = mfccs
    label = row.Class
 
    return pd.Series([feature, label])

temp = train.apply(parser, axis=1)

type(temp)

temp.columns = ['feature', 'label']

temp.label

temp.head()

from sklearn.preprocessing import LabelEncoder
from keras import utils as np_utils

X = np.array(temp.feature.tolist())
y = np.array(temp.label.tolist())

lb = LabelEncoder()

y = np_utils.to_categorical(lb.fit_transform(y))

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import Adam
from keras.utils import np_utils
from sklearn import metrics 

num_labels = y.shape[1]
filter_size = 2

#Creating Model
model = Sequential()

model.add(Dense(256, input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(num_labels))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')
model.summary()

model.fit(X, y, batch_size=32, epochs=100, validation_split = 0.2, verbose=1)

